{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get runs from baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Runs raymondl/tinystories-1m_play>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run e2e_bayesian_bayesian_seed-0_lpcoeff-0.05_logits-kl-1.0_lr-0.001_ratio-50.0_blocks.4.hook_resid_pre is not finished, skipping\n",
      "Run local_bayesian_bayesian_seed-0_lpcoeff-9e-05_in-to-out-1.0_lr-0.001_ratio-50.0_blocks.4.hook_resid_pre is not finished, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs: 100%|██████████| 105/105 [00:01<00:00, 59.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sparsity_coeff</th>\n",
       "      <th>L0</th>\n",
       "      <th>CELossIncrease</th>\n",
       "      <th>alive_dict_elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ds_seed-0_lpcoeff-50.0_logits-kl-0.5_in-to-ori...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.826889</td>\n",
       "      <td>0.146371</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ds_seed-0_lpcoeff-30.0_logits-kl-0.5_in-to-ori...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.282940</td>\n",
       "      <td>0.101824</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ds_seed-0_lpcoeff-20.0_logits-kl-0.5_in-to-ori...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.705284</td>\n",
       "      <td>0.075021</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ds_seed-0_lpcoeff-10.0_logits-kl-0.5_in-to-ori...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.539283</td>\n",
       "      <td>0.042366</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ds_seed-0_lpcoeff-5.0_logits-kl-0.5_in-to-orig...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.860445</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ds_seed-0_lpcoeff-3.0_logits-kl-0.5_in-to-orig...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.906909</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ds_seed-0_lpcoeff-1.0_logits-kl-0.5_in-to-orig...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.504038</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  sparsity_coeff  \\\n",
       "41  ds_seed-0_lpcoeff-50.0_logits-kl-0.5_in-to-ori...            50.0   \n",
       "45  ds_seed-0_lpcoeff-30.0_logits-kl-0.5_in-to-ori...            30.0   \n",
       "49  ds_seed-0_lpcoeff-20.0_logits-kl-0.5_in-to-ori...            20.0   \n",
       "53  ds_seed-0_lpcoeff-10.0_logits-kl-0.5_in-to-ori...            10.0   \n",
       "57  ds_seed-0_lpcoeff-5.0_logits-kl-0.5_in-to-orig...             5.0   \n",
       "61  ds_seed-0_lpcoeff-3.0_logits-kl-0.5_in-to-orig...             3.0   \n",
       "67  ds_seed-0_lpcoeff-1.0_logits-kl-0.5_in-to-orig...             1.0   \n",
       "\n",
       "            L0  CELossIncrease  alive_dict_elements  \n",
       "41   20.826889        0.146371                 1914  \n",
       "45   30.282940        0.101824                 1923  \n",
       "49   41.705284        0.075021                 1974  \n",
       "53   70.539283        0.042366                 1984  \n",
       "57  108.860445        0.021564                 2013  \n",
       "61  134.906909        0.014113                 2024  \n",
       "67  191.504038        0.003160                 2093  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n",
      "Moving model to device:  cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (blocks-4-hook_resid_pre): SAE(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=3200, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (decoder): Linear(in_features=3200, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blocks.4.hook_resid_pre']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.raw_sae_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Runs raymondl/tinystories-1m_play>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run e2e_bayesian_bayesian_seed-0_lpcoeff-0.05_logits-kl-1.0_lr-0.001_ratio-50.0_blocks.4.hook_resid_pre is not finished, skipping\n",
      "Run local_bayesian_bayesian_seed-0_lpcoeff-9e-05_in-to-out-1.0_lr-0.001_ratio-50.0_blocks.4.hook_resid_pre is not finished, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs: 100%|██████████| 105/105 [00:01<00:00, 59.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n",
      "Moving model to device:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval Steps:   0%|          | 0/20000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for dimension 0 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 127\u001b[39m\n\u001b[32m    125\u001b[39m heap = feature_top[f_global]\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rank \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TOP_K):\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     act = \u001b[43mtop_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlocal_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m]\u001b[49m.item()\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m act == \u001b[32m0\u001b[39m:             \u001b[38;5;66;03m# no activation – ignore\u001b[39;00m\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: index 64 is out of bounds for dimension 0 with size 64"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import json\n",
    "from collections.abc import Sequence\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import heapq\n",
    "from e2e_sae import SAETransformer\n",
    "from e2e_sae.log import logger\n",
    "from e2e_sae.plotting import plot_facet, plot_per_layer_metric\n",
    "from e2e_sae.scripts.analysis.plot_settings import (\n",
    "    SIMILAR_CE_RUNS,\n",
    "    SIMILAR_RUN_INFO,\n",
    "    STYLE_MAP,\n",
    ")\n",
    "from e2e_sae.scripts.analysis.utils import create_run_df, get_df_gpt2\n",
    "from e2e_sae.scripts.analysis.plot_performance import format_two_axes\n",
    "device = torch.device('cuda:0')\n",
    "api = wandb.Api(api_key='b8fa6d3104a0f99ee8a99f7c7659b893559f1097')\n",
    "project = \"raymondl/tinystories-1m_play\"\n",
    "runs = api.runs(project)\n",
    "print(runs)\n",
    "df = create_run_df(runs, per_layer_metrics=False, use_run_name=True, grad_norm=False)\n",
    "df = df[df['name'].str.contains('blocks.4.hook_resid_pre')]\n",
    "df = df[df['name'].str.contains('ds_seed')]\n",
    "df[['name', 'sparsity_coeff', 'L0', 'CELossIncrease', 'alive_dict_elements']]\n",
    "model = SAETransformer.from_wandb(f\"raymondl/tinystories-1m_play/{df['id'].iloc[0]}\").to('cuda:0')\n",
    "model.saes.eval()\n",
    "import math\n",
    "\n",
    "from datasets import IterableDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from e2e_sae.data import DatasetConfig, create_data_loader\n",
    "\n",
    "config = runs[0].config\n",
    "eval_config = DatasetConfig(**config['eval_data'])\n",
    "eval_loader = create_data_loader(\n",
    "    eval_config, batch_size=config['batch_size'], global_seed=config['seed']\n",
    ")[0]\n",
    "total_tokens = 0\n",
    "TOP_K = 20\n",
    "W = 64\n",
    "\n",
    "cache_positions: list[str] | None = None\n",
    "if config['loss']['in_to_orig'] is not None:\n",
    "    assert set(config['loss']['in_to_orig']['hook_positions']).issubset(\n",
    "        set(model.tlens_model.hook_dict.keys())\n",
    "    ), \"Some hook_positions in config.loss.in_to_orig.hook_positions are not in the model.\"\n",
    "    # Don't add a cache position if there is already an SAE at that position which will cache\n",
    "    # the inputs anyway\n",
    "    cache_positions = [\n",
    "        pos for pos in config.loss.in_to_orig.hook_positions if pos not in model.raw_sae_positions\n",
    "    ]\n",
    "if config.get('n_samples') is None:\n",
    "    # If streaming (i.e. if the dataset is an IterableDataset), we don't know the length\n",
    "    n_batches = None if isinstance(eval_loader.dataset, IterableDataset) else len(eval_loader)\n",
    "else:\n",
    "    n_batches = math.ceil(config['n_samples'] / config['batch_size'])\n",
    "\n",
    "feature_counts  = None          # will be [n_features] tensor\n",
    "feature_top     = None            # length = n_features; each is a min‑heap of (act, window_tokens, per_token_acts)\n",
    "\n",
    "for batch_idx, batch in tqdm(enumerate(eval_loader), total=n_batches, desc=\"Eval Steps\"):\n",
    "    if n_batches is not None and batch_idx >= n_batches:\n",
    "        break\n",
    "\n",
    "    tokens = batch[eval_config.column_name].to(device)\n",
    "    n_tokens = tokens.shape[0] * tokens.shape[1]\n",
    "    total_tokens += n_tokens\n",
    "\n",
    "    # Run through the SAE-augmented model\n",
    "    with torch.no_grad():\n",
    "        new_logits, new_acts = model.forward(\n",
    "            tokens=tokens,\n",
    "            sae_positions=model.raw_sae_positions,\n",
    "            cache_positions=None,\n",
    "        )\n",
    "    coeffs = new_acts['blocks.4.hook_resid_pre'].c # Batch_size x seq_len x num_dictionary_elements\n",
    "    B, S, N = coeffs.shape\n",
    "\n",
    "    if feature_counts is None  and feature_top is None:\n",
    "        feature_top = [ [] for _ in range(N) ]   # each is a min‑heap (max_act, toks, acts)\n",
    "        feature_counts = torch.zeros(N, dtype=torch.long, device=device)\n",
    "    \n",
    "    n_w = math.ceil(S / W)\n",
    "\n",
    "    #  --  reshape so axis‑1 indexes windows\n",
    "    #  unfold returns a view of shape [B, n_w, W, N]\n",
    "    coeffs_win = coeffs.unfold(dimension=1, size=W, step=W)   # [B, n_w, W, N]\n",
    "    # tokens_win just for later token retrieval (CPU)\n",
    "    tokens_win = tokens.unfold(1, W, W)                       # [B, n_w, W]\n",
    "\n",
    "    # max activation of each feature *within* each window  ->  [B, n_w, N]\n",
    "    max_per_win = coeffs_win.max(dim=2).values\n",
    "\n",
    "    # Count how many tokens fire for each feature (activation>0)\n",
    "    feature_counts += (coeffs > 0).sum(dim=(0,1)).to(torch.long)\n",
    "\n",
    "    ############################################################################\n",
    "    # 2.  For every feature, get its TOP_K windows (vectorised)\n",
    "    ############################################################################\n",
    "    # We process features in chunks to keep memory reasonable\n",
    "    CHUNK = 256                       # tune for your GPU vRAM\n",
    "    for start_f in range(0, N, CHUNK):\n",
    "        f_slice = slice(start_f, start_f+CHUNK)\n",
    "        # shape: [B*n_w, chunk]  (flatten batch+window so we can call topk once)\n",
    "        flat = max_per_win[:,:,f_slice].reshape(-1, max_per_win.shape[-1])\n",
    "\n",
    "        k_eff = min(TOP_K, flat.shape[0])\n",
    "        if k_eff == 0:\n",
    "            continue\n",
    "\n",
    "        # torch.topk over rows = windows, per feature (dim=0)\n",
    "        # top_vals, top_idx: [chunk, TOP_K]\n",
    "        top_vals, top_idx = torch.topk(flat.t(), k=k_eff, largest=True)\n",
    "\n",
    "        # turn flat index back into (b, w) pairs\n",
    "        b_idx  = (top_idx // n_w).cpu()\n",
    "        w_idx  = (top_idx %  n_w).cpu()\n",
    "        top_vals = top_vals.cpu()\n",
    "\n",
    "        for local_f, f_global in enumerate(range(start_f, min(start_f+CHUNK, N))):\n",
    "            heap = feature_top[f_global]\n",
    "            for rank in range(k_eff):\n",
    "                act = top_vals[local_f, rank].item()\n",
    "                if act == 0:             # no activation – ignore\n",
    "                    break\n",
    "                b   = b_idx [local_f, rank].item()\n",
    "                w   = w_idx [local_f, rank].item()\n",
    "                toks = tokens_win[b,w].cpu().tolist()\n",
    "                acts = coeffs_win [b,w,:,f_global].cpu().tolist()\n",
    "\n",
    "                if len(heap) < TOP_K:\n",
    "                    heapq.heappush(heap,(act, toks, acts))\n",
    "                elif act > heap[0][0]:   # replace worst\n",
    "                    heapq.heapreplace(heap,(act, toks, acts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'loss': {'sparsity': {'l': -0.1, 'r': 1.1, 'beta': 0.3333333333333333, 'coeff': 0.001, 'p_norm': 1, 'epsilon': 1e-06}, 'logits_kl': None, 'out_to_in': {'coeff': 1}, 'in_to_orig': None, 'out_to_orig': None}, 'saes': {'retrain_saes': False, 'sae_positions': ['blocks.4.hook_resid_pre'], 'pretrained_sae_paths': None, 'dict_size_to_input_ratio': 50}, 'seed': 0, 'save_dir': '/home/raymond/.temp/e2e_sae/e2e_sae/scripts/train_tlens_saes/out', 'eval_data': {'seed': None, 'n_ctx': 512, 'split': 'validation', 'streaming': True, 'column_name': 'input_ids', 'dataset_name': 'apollo-research/roneneldan-TinyStories-tokenizer-gpt2', 'is_tokenized': True, 'tokenizer_name': 'gpt2'}, 'n_samples': 400000, 'batch_size': 20, 'train_data': {'seed': None, 'n_ctx': 512, 'split': 'train', 'streaming': True, 'column_name': 'input_ids', 'dataset_name': 'apollo-research/roneneldan-TinyStories-tokenizer-gpt2', 'is_tokenized': True, 'tokenizer_name': 'gpt2'}, 'lr_schedule': 'cosine', 'max_grad_norm': 1, 'min_lr_factor': 0.1, 'wandb_project': 'tinystories-1m_play', 'eval_n_samples': 500, 'wandb_run_name': None, 'warmup_samples': 20000, 'cooldown_samples': 0, 'tlens_model_name': 'roneneldan/TinyStories-1M', 'tlens_model_path': None, 'effective_batch_size': 20, 'eval_every_n_samples': 40000, 'save_every_n_samples': None, 'wandb_run_name_prefix': 'local_', 'act_frequency_n_tokens': 500000, 'log_every_n_grad_steps': 20, 'collect_act_frequency_every_n_samples': 40000}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU vs No ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs: 100%|██████████| 40/40 [00:00<00:00, 18471.01it/s]\n",
      "Processing runs: 100%|██████████| 130/130 [00:02<00:00, 50.00it/s]\n",
      "2025-05-02 14:49:15 - INFO - Saved plot to plots/bayesian_e2e_relu_vs_no_relu_layer_4.png\n",
      "2025-05-02 14:49:15 - INFO - Saved SVG plot to plots/bayesian_e2e_relu_vs_no_relu_layer_4.svg\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api(api_key='b8fa6d3104a0f99ee8a99f7c7659b893559f1097')\n",
    "sweep_project = \"raymondl/tinystories-1m-e2e-bayesian-beta-sweep\"\n",
    "runs = api.runs(sweep_project)\n",
    "sweep_project_no_relu = \"raymondl/tinystories-1m-e2e-bayesian-beta-sweep-no-relu\"\n",
    "runs_no_relu = api.runs(sweep_project_no_relu)\n",
    "beta_values = set()\n",
    "df = create_run_df(runs, per_layer_metrics=False, use_run_name=True, grad_norm=False)\n",
    "\n",
    "df[\"grouping_type\"] = \"ReLU\"\n",
    "df_no_relu = create_run_df(runs_no_relu, per_layer_metrics=False, use_run_name=True, grad_norm=False)\n",
    "# Filter df_no_relu to only include runs that are in df\n",
    "df_no_relu = df_no_relu[df_no_relu[\"name\"].isin(df[\"name\"])]\n",
    "df_no_relu[\"grouping_type\"] = \"No ReLU\"\n",
    "df = pd.concat([df, df_no_relu], axis=0)\n",
    "plot_facet(\n",
    "    df=df,\n",
    "    xs=[\"CELossIncrease\"],\n",
    "    y=\"L0\",\n",
    "    facet_by=\"layer\",\n",
    "    facet_vals=[4],\n",
    "    line_by=\"grouping_type\",\n",
    "    xlabels=[\"CE Loss Increase\"],\n",
    "    ylabel=\"L0\",\n",
    "    legend_title=\"Beta Value\",\n",
    "    axis_formatter=None,\n",
    "    out_file=\"plots/bayesian_e2e_relu_vs_no_relu_layer_4.png\",\n",
    "    xlims=[{4: (None, None)}, {4: (None, None)}],\n",
    "    ylim={4: (None, None)},\n",
    "    styles=STYLE_MAP,\n",
    "    plot_type='line',\n",
    "    annotate_col=\"sparsity_coeff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs: 100%|██████████| 130/130 [00:02<00:00, 50.49it/s]\n",
      "2025-05-02 15:10:32 - INFO - Saved plot to plots/bayesian_e2e_learning_rates_layer_4.png\n",
      "2025-05-02 15:10:32 - INFO - Saved SVG plot to plots/bayesian_e2e_learning_rates_layer_4.svg\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api(api_key='b8fa6d3104a0f99ee8a99f7c7659b893559f1097')\n",
    "project = \"raymondl/tinystories-1m-e2e-bayesian-beta-sweep-no-relu\"\n",
    "runs = api.runs(project)\n",
    "df = create_run_df(runs, per_layer_metrics=False, use_run_name=True, grad_norm=False)\n",
    "df = df[df['name'].str.contains('beta_0.5_bayesian_seed-0')]\n",
    "df[\"grouping_type\"] = df[\"name\"].apply(lambda x: f\"LR: {x.split('lr-')[-1].split('_')[0]}\")\n",
    "plot_facet(\n",
    "    df=df,\n",
    "    xs=[\"CELossIncrease\"],\n",
    "    y=\"L0\",\n",
    "    facet_by=\"layer\",\n",
    "    facet_vals=[4],\n",
    "    line_by=\"grouping_type\",\n",
    "    xlabels=[\"CE Loss Increase\"],\n",
    "    ylabel=\"L0\",\n",
    "    legend_title=\"Beta Value\",\n",
    "    axis_formatter=None,\n",
    "    out_file=\"plots/bayesian_e2e_learning_rates_layer_4.png\",\n",
    "    xlims=[{4: (None, None)}, {4: (None, None)}],\n",
    "    ylim={4: (None, None)},\n",
    "    styles=STYLE_MAP,\n",
    "    plot_type='line',\n",
    "    annotate_col=\"sparsity_coeff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyStories-1M Comparisons with Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs:   0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run e2e_bayesian_bayesian_seed-0_lpcoeff-0.05_logits-kl-1.0_lr-0.001_ratio-50.0_blocks.4.hook_resid_pre is not finished, skipping\n",
      "Run local_bayesian_bayesian_seed-0_lpcoeff-9e-05_in-to-out-1.0_lr-0.001_ratio-50.0_blocks.4.hook_resid_pre is not finished, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs: 100%|██████████| 105/105 [00:01<00:00, 53.08it/s]\n",
      "Processing runs: 100%|██████████| 51/51 [00:00<00:00, 643.18it/s]\n",
      "/tmp/ipykernel_3183258/1399092007.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df2], axis=0)\n",
      "2025-05-03 18:24:07 - INFO - Saved plot to plots/l0_vs_ce_loss_layer_4.png\n",
      "2025-05-03 18:24:07 - INFO - Saved SVG plot to plots/l0_vs_ce_loss_layer_4.svg\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api(api_key='b8fa6d3104a0f99ee8a99f7c7659b893559f1097')\n",
    "project = \"raymondl/tinystories-1m_play\"\n",
    "runs = api.runs(project)\n",
    "df = create_run_df(runs, per_layer_metrics=False, use_run_name=True, grad_norm=False)\n",
    "df = df[df['name'].str.contains('blocks.4.hook_resid_pre')]\n",
    "df = df[df['name'].str.contains('local_seed') | df['name'].str.contains('e2e_seed') | df['name'].str.contains('ds_seed')]\n",
    "def assign_group(run_name: str):\n",
    "    # if 'e2e_bayesian' in run_name or 'beta_0.5' in run_name:\n",
    "    #     return 'e2e (bayesian)'\n",
    "    # elif 'local_bayesian' in run_name:\n",
    "    #     return 'local (bayesian)'\n",
    "    if 'ds' in run_name:\n",
    "        return 'ds'\n",
    "    elif 'e2e' in run_name:\n",
    "        return 'e2e'\n",
    "    else:\n",
    "        return 'local'\n",
    "df[\"grouping_type\"] = df[\"name\"].apply(assign_group)\n",
    "\n",
    "project = \"tinystories-1m-e2e-bayesian-beta-annealing\"\n",
    "runs = api.runs(project)\n",
    "df2 = create_run_df(runs, per_layer_metrics=False, use_run_name=True, grad_norm=False)\n",
    "df2 = df2[df2['name'].str.contains('linear_annealing')]\n",
    "def assign_group2(run_name: str):\n",
    "    beta_value = f\"{run_name.split('beta_')[-1].split('_')[0]}\"\n",
    "    return f\"e2e (bayesian) {beta_value}\"\n",
    "df2[\"grouping_type\"] = df2[\"name\"].apply(assign_group2)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([df, df2], axis=0)\n",
    "\n",
    "# df = df[df['CELossIncrease'] < 1]\n",
    "# df = df[df['L0'] < 100]\n",
    "\n",
    "\n",
    "plot_facet(\n",
    "    df=df,\n",
    "    xs=[\"L0\", \"alive_dict_elements\"],\n",
    "    y=\"CELossIncrease\",\n",
    "    facet_by=\"layer\",\n",
    "    facet_vals=[4],\n",
    "    line_by=\"grouping_type\",\n",
    "    xlabels=[\"L0\", \"Alive Dict Elements\"],\n",
    "    ylabel=\"CE Loss Increase\",\n",
    "    legend_title=\"SAE Type\",\n",
    "    axis_formatter=partial(format_two_axes, better_labels=True),\n",
    "    out_file=\"plots/l0_vs_ce_loss_layer_4.png\",\n",
    "    xlims=[{4: (None, None)}, {4: (None, None)}],\n",
    "    ylim={4: (.5, 0)},\n",
    "    styles=STYLE_MAP,\n",
    "    plot_type='line',\n",
    "    # annotate_col=\"sparsity_coeff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs:   0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run local_bayesian_bayesian_seed-0_lpcoeff-9e-05_in-to-out-1.0_lr-0.001_ratio-50.0_blocks.4.hook_resid_pre is not finished, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing runs: 100%|██████████| 61/61 [00:00<00:00, 182.75it/s]\n",
      "2025-05-03 18:18:06 - INFO - Saved plot to plots/l0_vs_ce_loss_local_layer_4.png\n",
      "2025-05-03 18:18:06 - INFO - Saved SVG plot to plots/l0_vs_ce_loss_local_layer_4.svg\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api(api_key='b8fa6d3104a0f99ee8a99f7c7659b893559f1097')\n",
    "project = \"raymondl/tinystories-1m_play\"\n",
    "runs = api.runs(project, filters={\"tags\": \"local\"})\n",
    "df = create_run_df(runs, per_layer_metrics=False, use_run_name=True, grad_norm=False)\n",
    "\n",
    "def assign_group(name):\n",
    "    if \"bayesian\" in name:\n",
    "        return \"local (bayesian)\"\n",
    "    else:\n",
    "        return \"local\"\n",
    "\n",
    "df[\"grouping_type\"] = df[\"name\"].apply(assign_group)\n",
    "\n",
    "plot_facet(\n",
    "    df=df,\n",
    "    xs=[\"CELossIncrease\", \"out_to_in\"],\n",
    "    y=\"L0\",\n",
    "    facet_by=\"layer\",\n",
    "    facet_vals=[4],\n",
    "    line_by=\"grouping_type\",\n",
    "    xlabels=[\"CE Loss Increase\", \"Reconstruction MSE\"],\n",
    "    ylabel=\"L0\",\n",
    "    legend_title=\"SAE Type\",\n",
    "    axis_formatter=partial(format_two_axes, better_labels=True),\n",
    "    out_file=\"plots/l0_vs_ce_loss_local_layer_4.png\",\n",
    "    xlims=[{4: (-0.5, 10)}, {4: (None, None)}],\n",
    "    ylim={4: (None, None)},\n",
    "    styles=STYLE_MAP,\n",
    "    \n",
    "    annotate_col=\"sparsity_coeff\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
